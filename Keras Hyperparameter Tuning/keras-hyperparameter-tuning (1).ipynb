{"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"sourceId":482,"sourceType":"datasetVersion","datasetId":228}],"dockerImageVersionId":30746,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.status.busy":"2024-07-20T07:08:37.723361Z","iopub.execute_input":"2024-07-20T07:08:37.723850Z","iopub.status.idle":"2024-07-20T07:08:38.150647Z","shell.execute_reply.started":"2024-07-20T07:08:37.723802Z","shell.execute_reply":"2024-07-20T07:08:38.149199Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/pima-indians-diabetes-database/diabetes.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd","metadata":{"execution":{"iopub.status.busy":"2024-07-20T07:08:38.152304Z","iopub.execute_input":"2024-07-20T07:08:38.153242Z","iopub.status.idle":"2024-07-20T07:08:38.160565Z","shell.execute_reply.started":"2024-07-20T07:08:38.153197Z","shell.execute_reply":"2024-07-20T07:08:38.159292Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"df=pd.read_csv('/kaggle/input/pima-indians-diabetes-database/diabetes.csv')","metadata":{"execution":{"iopub.status.busy":"2024-07-20T07:08:38.162512Z","iopub.execute_input":"2024-07-20T07:08:38.163025Z","iopub.status.idle":"2024-07-20T07:08:38.180563Z","shell.execute_reply.started":"2024-07-20T07:08:38.162981Z","shell.execute_reply":"2024-07-20T07:08:38.179281Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"print(df)","metadata":{"execution":{"iopub.status.busy":"2024-07-20T07:08:38.184575Z","iopub.execute_input":"2024-07-20T07:08:38.185414Z","iopub.status.idle":"2024-07-20T07:08:38.200604Z","shell.execute_reply.started":"2024-07-20T07:08:38.185368Z","shell.execute_reply":"2024-07-20T07:08:38.198963Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"     Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n0              6      148             72             35        0  33.6   \n1              1       85             66             29        0  26.6   \n2              8      183             64              0        0  23.3   \n3              1       89             66             23       94  28.1   \n4              0      137             40             35      168  43.1   \n..           ...      ...            ...            ...      ...   ...   \n763           10      101             76             48      180  32.9   \n764            2      122             70             27        0  36.8   \n765            5      121             72             23      112  26.2   \n766            1      126             60              0        0  30.1   \n767            1       93             70             31        0  30.4   \n\n     DiabetesPedigreeFunction  Age  Outcome  \n0                       0.627   50        1  \n1                       0.351   31        0  \n2                       0.672   32        1  \n3                       0.167   21        0  \n4                       2.288   33        1  \n..                        ...  ...      ...  \n763                     0.171   63        0  \n764                     0.340   27        0  \n765                     0.245   30        0  \n766                     0.349   47        1  \n767                     0.315   23        0  \n\n[768 rows x 9 columns]\n","output_type":"stream"}]},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2024-07-20T07:08:38.202091Z","iopub.execute_input":"2024-07-20T07:08:38.203534Z","iopub.status.idle":"2024-07-20T07:08:38.227613Z","shell.execute_reply.started":"2024-07-20T07:08:38.203487Z","shell.execute_reply":"2024-07-20T07:08:38.225856Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n0            6      148             72             35        0  33.6   \n1            1       85             66             29        0  26.6   \n2            8      183             64              0        0  23.3   \n3            1       89             66             23       94  28.1   \n4            0      137             40             35      168  43.1   \n\n   DiabetesPedigreeFunction  Age  Outcome  \n0                     0.627   50        1  \n1                     0.351   31        0  \n2                     0.672   32        1  \n3                     0.167   21        0  \n4                     2.288   33        1  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Pregnancies</th>\n      <th>Glucose</th>\n      <th>BloodPressure</th>\n      <th>SkinThickness</th>\n      <th>Insulin</th>\n      <th>BMI</th>\n      <th>DiabetesPedigreeFunction</th>\n      <th>Age</th>\n      <th>Outcome</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>6</td>\n      <td>148</td>\n      <td>72</td>\n      <td>35</td>\n      <td>0</td>\n      <td>33.6</td>\n      <td>0.627</td>\n      <td>50</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>85</td>\n      <td>66</td>\n      <td>29</td>\n      <td>0</td>\n      <td>26.6</td>\n      <td>0.351</td>\n      <td>31</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>8</td>\n      <td>183</td>\n      <td>64</td>\n      <td>0</td>\n      <td>0</td>\n      <td>23.3</td>\n      <td>0.672</td>\n      <td>32</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>89</td>\n      <td>66</td>\n      <td>23</td>\n      <td>94</td>\n      <td>28.1</td>\n      <td>0.167</td>\n      <td>21</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>137</td>\n      <td>40</td>\n      <td>35</td>\n      <td>168</td>\n      <td>43.1</td>\n      <td>2.288</td>\n      <td>33</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"df.corr()['Outcome']","metadata":{"execution":{"iopub.status.busy":"2024-07-20T07:08:38.229353Z","iopub.execute_input":"2024-07-20T07:08:38.229728Z","iopub.status.idle":"2024-07-20T07:08:38.239778Z","shell.execute_reply.started":"2024-07-20T07:08:38.229696Z","shell.execute_reply":"2024-07-20T07:08:38.238479Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"Pregnancies                 0.221898\nGlucose                     0.466581\nBloodPressure               0.065068\nSkinThickness               0.074752\nInsulin                     0.130548\nBMI                         0.292695\nDiabetesPedigreeFunction    0.173844\nAge                         0.238356\nOutcome                     1.000000\nName: Outcome, dtype: float64"},"metadata":{}}]},{"cell_type":"code","source":"X=df.iloc[:,:-1].values\nY=df.iloc[:,-1].values","metadata":{"execution":{"iopub.status.busy":"2024-07-20T07:08:38.241092Z","iopub.execute_input":"2024-07-20T07:08:38.241562Z","iopub.status.idle":"2024-07-20T07:08:38.251113Z","shell.execute_reply.started":"2024-07-20T07:08:38.241488Z","shell.execute_reply":"2024-07-20T07:08:38.249760Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\nscaler=StandardScaler()","metadata":{"execution":{"iopub.status.busy":"2024-07-20T07:08:38.252873Z","iopub.execute_input":"2024-07-20T07:08:38.253280Z","iopub.status.idle":"2024-07-20T07:08:38.782253Z","shell.execute_reply.started":"2024-07-20T07:08:38.253246Z","shell.execute_reply":"2024-07-20T07:08:38.781062Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"X=scaler.fit_transform(X)","metadata":{"execution":{"iopub.status.busy":"2024-07-20T07:08:38.783982Z","iopub.execute_input":"2024-07-20T07:08:38.784446Z","iopub.status.idle":"2024-07-20T07:08:38.792384Z","shell.execute_reply.started":"2024-07-20T07:08:38.784404Z","shell.execute_reply":"2024-07-20T07:08:38.791050Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"x=scaler.fit_transform(X)","metadata":{"execution":{"iopub.status.busy":"2024-07-20T07:08:38.794345Z","iopub.execute_input":"2024-07-20T07:08:38.794848Z","iopub.status.idle":"2024-07-20T07:08:38.803365Z","shell.execute_reply.started":"2024-07-20T07:08:38.794806Z","shell.execute_reply":"2024-07-20T07:08:38.802200Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"X.shape","metadata":{"execution":{"iopub.status.busy":"2024-07-20T07:08:38.804950Z","iopub.execute_input":"2024-07-20T07:08:38.805423Z","iopub.status.idle":"2024-07-20T07:08:38.816999Z","shell.execute_reply.started":"2024-07-20T07:08:38.805381Z","shell.execute_reply":"2024-07-20T07:08:38.815750Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"(768, 8)"},"metadata":{}}]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train,X_test,Y_train,Y_test=train_test_split(X,Y,test_size=0.2,random_state=1)","metadata":{"execution":{"iopub.status.busy":"2024-07-20T07:08:38.818538Z","iopub.execute_input":"2024-07-20T07:08:38.818898Z","iopub.status.idle":"2024-07-20T07:08:38.848643Z","shell.execute_reply.started":"2024-07-20T07:08:38.818869Z","shell.execute_reply":"2024-07-20T07:08:38.847565Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"import tensorflow\nfrom tensorflow import keras\nfrom keras import Sequential \nfrom keras.layers import Dense","metadata":{"execution":{"iopub.status.busy":"2024-07-20T07:08:38.852569Z","iopub.execute_input":"2024-07-20T07:08:38.853222Z","iopub.status.idle":"2024-07-20T07:08:42.626821Z","shell.execute_reply.started":"2024-07-20T07:08:38.853188Z","shell.execute_reply":"2024-07-20T07:08:42.625632Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stderr","text":"2024-07-20 07:08:39.349350: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-07-20 07:08:39.349410: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-07-20 07:08:39.351284: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}]},{"cell_type":"code","source":"\n# Initialize a sequential model\nmodel = Sequential()\n\n# Add a dense (fully connected) layer with 32 units, ReLU activation, and an input dimension of 8\nmodel.add(Dense(32, activation='relu', input_dim=8))\n\n# Add another dense layer with 1 unit and sigmoid activation (for binary classification)\nmodel.add(Dense(1, activation='sigmoid'))\n\n# Compile the model with the Adam optimizer, binary crossentropy loss, and accuracy metric\nmodel.compile(optimizer='Adam', loss='binary_crossentropy', metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2024-07-20T07:08:42.628293Z","iopub.execute_input":"2024-07-20T07:08:42.629017Z","iopub.status.idle":"2024-07-20T07:08:42.710424Z","shell.execute_reply.started":"2024-07-20T07:08:42.628981Z","shell.execute_reply":"2024-07-20T07:08:42.709038Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n","output_type":"stream"}]},{"cell_type":"code","source":"model.fit(X_train,Y_train,batch_size=32,epochs=100,validation_data=(X_test,Y_test))","metadata":{"execution":{"iopub.status.busy":"2024-07-20T07:08:42.711736Z","iopub.execute_input":"2024-07-20T07:08:42.712113Z","iopub.status.idle":"2024-07-20T07:08:52.751218Z","shell.execute_reply.started":"2024-07-20T07:08:42.712058Z","shell.execute_reply":"2024-07-20T07:08:52.749987Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"Epoch 1/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.6151 - loss: 0.6417 - val_accuracy: 0.6948 - val_loss: 0.6103\nEpoch 2/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6693 - loss: 0.5824 - val_accuracy: 0.7338 - val_loss: 0.5684\nEpoch 3/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7285 - loss: 0.5472 - val_accuracy: 0.7597 - val_loss: 0.5393\nEpoch 4/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7066 - loss: 0.5455 - val_accuracy: 0.7662 - val_loss: 0.5202\nEpoch 5/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7300 - loss: 0.5219 - val_accuracy: 0.7662 - val_loss: 0.5054\nEpoch 6/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7238 - loss: 0.4969 - val_accuracy: 0.7662 - val_loss: 0.4930\nEpoch 7/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7586 - loss: 0.4811 - val_accuracy: 0.7532 - val_loss: 0.4857\nEpoch 8/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7211 - loss: 0.5015 - val_accuracy: 0.7532 - val_loss: 0.4815\nEpoch 9/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7602 - loss: 0.4694 - val_accuracy: 0.7597 - val_loss: 0.4757\nEpoch 10/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7563 - loss: 0.4710 - val_accuracy: 0.7597 - val_loss: 0.4708\nEpoch 11/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7469 - loss: 0.4827 - val_accuracy: 0.7597 - val_loss: 0.4658\nEpoch 12/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7552 - loss: 0.4734 - val_accuracy: 0.7597 - val_loss: 0.4630\nEpoch 13/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7504 - loss: 0.4687 - val_accuracy: 0.7597 - val_loss: 0.4617\nEpoch 14/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7750 - loss: 0.4615 - val_accuracy: 0.7532 - val_loss: 0.4606\nEpoch 15/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7879 - loss: 0.4453 - val_accuracy: 0.7532 - val_loss: 0.4592\nEpoch 16/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7841 - loss: 0.4424 - val_accuracy: 0.7468 - val_loss: 0.4562\nEpoch 17/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7702 - loss: 0.4528 - val_accuracy: 0.7532 - val_loss: 0.4548\nEpoch 18/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7525 - loss: 0.4769 - val_accuracy: 0.7532 - val_loss: 0.4539\nEpoch 19/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7555 - loss: 0.4566 - val_accuracy: 0.7597 - val_loss: 0.4539\nEpoch 20/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7569 - loss: 0.4804 - val_accuracy: 0.7597 - val_loss: 0.4536\nEpoch 21/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7776 - loss: 0.4690 - val_accuracy: 0.7532 - val_loss: 0.4522\nEpoch 22/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7615 - loss: 0.4501 - val_accuracy: 0.7532 - val_loss: 0.4512\nEpoch 23/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7681 - loss: 0.4453 - val_accuracy: 0.7532 - val_loss: 0.4525\nEpoch 24/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7951 - loss: 0.4163 - val_accuracy: 0.7532 - val_loss: 0.4522\nEpoch 25/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7717 - loss: 0.4611 - val_accuracy: 0.7597 - val_loss: 0.4525\nEpoch 26/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7829 - loss: 0.4434 - val_accuracy: 0.7597 - val_loss: 0.4531\nEpoch 27/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7966 - loss: 0.4243 - val_accuracy: 0.7662 - val_loss: 0.4516\nEpoch 28/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7866 - loss: 0.4401 - val_accuracy: 0.7662 - val_loss: 0.4524\nEpoch 29/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7686 - loss: 0.4536 - val_accuracy: 0.7662 - val_loss: 0.4527\nEpoch 30/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7460 - loss: 0.4734 - val_accuracy: 0.7662 - val_loss: 0.4516\nEpoch 31/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7805 - loss: 0.4439 - val_accuracy: 0.7727 - val_loss: 0.4521\nEpoch 32/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7722 - loss: 0.4496 - val_accuracy: 0.7727 - val_loss: 0.4513\nEpoch 33/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7733 - loss: 0.4282 - val_accuracy: 0.7727 - val_loss: 0.4509\nEpoch 34/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7637 - loss: 0.4769 - val_accuracy: 0.7727 - val_loss: 0.4505\nEpoch 35/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7709 - loss: 0.4549 - val_accuracy: 0.7727 - val_loss: 0.4509\nEpoch 36/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7890 - loss: 0.4297 - val_accuracy: 0.7727 - val_loss: 0.4510\nEpoch 37/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7880 - loss: 0.4339 - val_accuracy: 0.7727 - val_loss: 0.4505\nEpoch 38/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7684 - loss: 0.4406 - val_accuracy: 0.7792 - val_loss: 0.4501\nEpoch 39/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7809 - loss: 0.4423 - val_accuracy: 0.7792 - val_loss: 0.4504\nEpoch 40/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7620 - loss: 0.4567 - val_accuracy: 0.7727 - val_loss: 0.4509\nEpoch 41/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7807 - loss: 0.4325 - val_accuracy: 0.7792 - val_loss: 0.4522\nEpoch 42/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7966 - loss: 0.4327 - val_accuracy: 0.7727 - val_loss: 0.4518\nEpoch 43/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7571 - loss: 0.4573 - val_accuracy: 0.7727 - val_loss: 0.4503\nEpoch 44/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7541 - loss: 0.4672 - val_accuracy: 0.7727 - val_loss: 0.4502\nEpoch 45/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7608 - loss: 0.4459 - val_accuracy: 0.7792 - val_loss: 0.4497\nEpoch 46/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7673 - loss: 0.4613 - val_accuracy: 0.7792 - val_loss: 0.4499\nEpoch 47/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7643 - loss: 0.4474 - val_accuracy: 0.7792 - val_loss: 0.4504\nEpoch 48/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7888 - loss: 0.4362 - val_accuracy: 0.7792 - val_loss: 0.4507\nEpoch 49/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8004 - loss: 0.4079 - val_accuracy: 0.7922 - val_loss: 0.4515\nEpoch 50/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7787 - loss: 0.4564 - val_accuracy: 0.7857 - val_loss: 0.4514\nEpoch 51/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7552 - loss: 0.4686 - val_accuracy: 0.7792 - val_loss: 0.4501\nEpoch 52/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7859 - loss: 0.4413 - val_accuracy: 0.7792 - val_loss: 0.4505\nEpoch 53/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7726 - loss: 0.4361 - val_accuracy: 0.7792 - val_loss: 0.4498\nEpoch 54/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7914 - loss: 0.4189 - val_accuracy: 0.7857 - val_loss: 0.4506\nEpoch 55/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7854 - loss: 0.4453 - val_accuracy: 0.7857 - val_loss: 0.4501\nEpoch 56/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8025 - loss: 0.4100 - val_accuracy: 0.7662 - val_loss: 0.4519\nEpoch 57/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7810 - loss: 0.4262 - val_accuracy: 0.7662 - val_loss: 0.4511\nEpoch 58/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7752 - loss: 0.4217 - val_accuracy: 0.7727 - val_loss: 0.4505\nEpoch 59/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7807 - loss: 0.4445 - val_accuracy: 0.7857 - val_loss: 0.4520\nEpoch 60/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8043 - loss: 0.4072 - val_accuracy: 0.7857 - val_loss: 0.4509\nEpoch 61/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7980 - loss: 0.4380 - val_accuracy: 0.7857 - val_loss: 0.4519\nEpoch 62/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7877 - loss: 0.4180 - val_accuracy: 0.7857 - val_loss: 0.4526\nEpoch 63/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7945 - loss: 0.4251 - val_accuracy: 0.7857 - val_loss: 0.4516\nEpoch 64/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8025 - loss: 0.4179 - val_accuracy: 0.7857 - val_loss: 0.4520\nEpoch 65/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7514 - loss: 0.4456 - val_accuracy: 0.7792 - val_loss: 0.4519\nEpoch 66/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8231 - loss: 0.4007 - val_accuracy: 0.7792 - val_loss: 0.4529\nEpoch 67/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7668 - loss: 0.4348 - val_accuracy: 0.7727 - val_loss: 0.4545\nEpoch 68/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7866 - loss: 0.4245 - val_accuracy: 0.7857 - val_loss: 0.4521\nEpoch 69/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7974 - loss: 0.4085 - val_accuracy: 0.7792 - val_loss: 0.4523\nEpoch 70/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7718 - loss: 0.4369 - val_accuracy: 0.7792 - val_loss: 0.4520\nEpoch 71/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8062 - loss: 0.4067 - val_accuracy: 0.7857 - val_loss: 0.4517\nEpoch 72/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7921 - loss: 0.4119 - val_accuracy: 0.7922 - val_loss: 0.4517\nEpoch 73/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7834 - loss: 0.4378 - val_accuracy: 0.7857 - val_loss: 0.4529\nEpoch 74/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7732 - loss: 0.4547 - val_accuracy: 0.7987 - val_loss: 0.4505\nEpoch 75/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7854 - loss: 0.4232 - val_accuracy: 0.7922 - val_loss: 0.4506\nEpoch 76/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7679 - loss: 0.4573 - val_accuracy: 0.7922 - val_loss: 0.4510\nEpoch 77/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7887 - loss: 0.4393 - val_accuracy: 0.7987 - val_loss: 0.4510\nEpoch 78/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7877 - loss: 0.4275 - val_accuracy: 0.7987 - val_loss: 0.4512\nEpoch 79/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7900 - loss: 0.4114 - val_accuracy: 0.7922 - val_loss: 0.4501\nEpoch 80/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7769 - loss: 0.4598 - val_accuracy: 0.7922 - val_loss: 0.4512\nEpoch 81/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7867 - loss: 0.4279 - val_accuracy: 0.7987 - val_loss: 0.4521\nEpoch 82/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7685 - loss: 0.4459 - val_accuracy: 0.7987 - val_loss: 0.4518\nEpoch 83/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7930 - loss: 0.4052 - val_accuracy: 0.7922 - val_loss: 0.4514\nEpoch 84/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7904 - loss: 0.4234 - val_accuracy: 0.7922 - val_loss: 0.4509\nEpoch 85/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8225 - loss: 0.3934 - val_accuracy: 0.7857 - val_loss: 0.4517\nEpoch 86/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7894 - loss: 0.4317 - val_accuracy: 0.7857 - val_loss: 0.4522\nEpoch 87/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7875 - loss: 0.4326 - val_accuracy: 0.7922 - val_loss: 0.4510\nEpoch 88/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7956 - loss: 0.4314 - val_accuracy: 0.7922 - val_loss: 0.4519\nEpoch 89/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7961 - loss: 0.4271 - val_accuracy: 0.7987 - val_loss: 0.4523\nEpoch 90/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8041 - loss: 0.4107 - val_accuracy: 0.7987 - val_loss: 0.4523\nEpoch 91/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8155 - loss: 0.4057 - val_accuracy: 0.7922 - val_loss: 0.4536\nEpoch 92/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7931 - loss: 0.4166 - val_accuracy: 0.7987 - val_loss: 0.4532\nEpoch 93/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7793 - loss: 0.4118 - val_accuracy: 0.7987 - val_loss: 0.4535\nEpoch 94/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8033 - loss: 0.4322 - val_accuracy: 0.7987 - val_loss: 0.4541\nEpoch 95/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7857 - loss: 0.4170 - val_accuracy: 0.7922 - val_loss: 0.4533\nEpoch 96/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7838 - loss: 0.4238 - val_accuracy: 0.7987 - val_loss: 0.4535\nEpoch 97/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7957 - loss: 0.3987 - val_accuracy: 0.7857 - val_loss: 0.4549\nEpoch 98/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7889 - loss: 0.4202 - val_accuracy: 0.7857 - val_loss: 0.4521\nEpoch 99/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7989 - loss: 0.4059 - val_accuracy: 0.7857 - val_loss: 0.4513\nEpoch 100/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8007 - loss: 0.4280 - val_accuracy: 0.7857 - val_loss: 0.4514\n","output_type":"stream"},{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"<keras.src.callbacks.history.History at 0x7d25b71e0fd0>"},"metadata":{}}]},{"cell_type":"code","source":"#1.how to select appropriate optimizer\n#2.number of the nodes in the layer \n#3.how to select the number of the layers\n#4.all in one model\n","metadata":{"execution":{"iopub.status.busy":"2024-07-20T07:08:52.752776Z","iopub.execute_input":"2024-07-20T07:08:52.753205Z","iopub.status.idle":"2024-07-20T07:08:52.758215Z","shell.execute_reply.started":"2024-07-20T07:08:52.753170Z","shell.execute_reply":"2024-07-20T07:08:52.756950Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"# pip install -U keras-tuner","metadata":{"execution":{"iopub.status.busy":"2024-07-20T07:08:52.759602Z","iopub.execute_input":"2024-07-20T07:08:52.760013Z","iopub.status.idle":"2024-07-20T07:08:52.775055Z","shell.execute_reply.started":"2024-07-20T07:08:52.759984Z","shell.execute_reply":"2024-07-20T07:08:52.773532Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"import keras_tuner as kt","metadata":{"execution":{"iopub.status.busy":"2024-07-20T07:08:52.776540Z","iopub.execute_input":"2024-07-20T07:08:52.776993Z","iopub.status.idle":"2024-07-20T07:08:52.838938Z","shell.execute_reply.started":"2024-07-20T07:08:52.776948Z","shell.execute_reply":"2024-07-20T07:08:52.837764Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"import keras_tuner as kt\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense\n\ndef build_model(hp):\n    model = Sequential()\n    model.add(Dense(32, activation='relu', input_dim=8))\n    model.add(Dense(1, activation='sigmoid'))\n    optimizer = hp.Choice('optimizer', values=['adam', 'sgd', 'rmsprop', 'adadelta'])\n    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n    return model\n","metadata":{"execution":{"iopub.status.busy":"2024-07-20T07:08:52.840471Z","iopub.execute_input":"2024-07-20T07:08:52.841465Z","iopub.status.idle":"2024-07-20T07:08:52.859716Z","shell.execute_reply.started":"2024-07-20T07:08:52.841421Z","shell.execute_reply":"2024-07-20T07:08:52.858513Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"\ntuner = kt.RandomSearch(build_model, objective='val_accuracy', max_trials=5)\n","metadata":{"execution":{"iopub.status.busy":"2024-07-20T07:08:52.861244Z","iopub.execute_input":"2024-07-20T07:08:52.862188Z","iopub.status.idle":"2024-07-20T07:08:52.877429Z","shell.execute_reply.started":"2024-07-20T07:08:52.862146Z","shell.execute_reply":"2024-07-20T07:08:52.876082Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":"Reloading Tuner from ./untitled_project/tuner0.json\n","output_type":"stream"}]},{"cell_type":"code","source":"print(tuner.search(X_train,Y_train,epochs=10,validation_data=(X_test,Y_test)))\n","metadata":{"execution":{"iopub.status.busy":"2024-07-20T07:08:52.878887Z","iopub.execute_input":"2024-07-20T07:08:52.879251Z","iopub.status.idle":"2024-07-20T07:08:52.886370Z","shell.execute_reply.started":"2024-07-20T07:08:52.879222Z","shell.execute_reply":"2024-07-20T07:08:52.885154Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"None\n","output_type":"stream"}]},{"cell_type":"code","source":"tuner.get_best_hyperparameters()[0].values","metadata":{"execution":{"iopub.status.busy":"2024-07-20T07:11:50.915293Z","iopub.execute_input":"2024-07-20T07:11:50.915743Z","iopub.status.idle":"2024-07-20T07:11:50.923352Z","shell.execute_reply.started":"2024-07-20T07:11:50.915709Z","shell.execute_reply":"2024-07-20T07:11:50.922212Z"},"trusted":true},"execution_count":25,"outputs":[{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"{'optimizer': 'rmsprop'}"},"metadata":{}}]},{"cell_type":"code","source":"# Get the best model\nbest_model = tuner.get_best_models(num_models=1)[0]","metadata":{"execution":{"iopub.status.busy":"2024-07-20T07:13:14.860533Z","iopub.execute_input":"2024-07-20T07:13:14.861632Z","iopub.status.idle":"2024-07-20T07:13:15.540171Z","shell.execute_reply.started":"2024-07-20T07:13:14.861589Z","shell.execute_reply":"2024-07-20T07:13:15.539007Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"execution":{"iopub.status.busy":"2024-07-20T07:13:31.712425Z","iopub.execute_input":"2024-07-20T07:13:31.713548Z","iopub.status.idle":"2024-07-20T07:13:31.735298Z","shell.execute_reply.started":"2024-07-20T07:13:31.713500Z","shell.execute_reply":"2024-07-20T07:13:31.734007Z"},"trusted":true},"execution_count":29,"outputs":[{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"sequential\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │           \u001b[38;5;34m288\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m33\u001b[0m │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">288</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m321\u001b[0m (1.25 KB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">321</span> (1.25 KB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m321\u001b[0m (1.25 KB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">321</span> (1.25 KB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"},"metadata":{}}]},{"cell_type":"code","source":"model.fit(X_train,Y_train,batch_size=32,epochs=100,initial_epoch=6,validation_data=(X_test,Y_test))","metadata":{"execution":{"iopub.status.busy":"2024-07-20T07:15:42.765979Z","iopub.execute_input":"2024-07-20T07:15:42.767090Z","iopub.status.idle":"2024-07-20T07:15:52.473608Z","shell.execute_reply.started":"2024-07-20T07:15:42.767049Z","shell.execute_reply":"2024-07-20T07:15:52.472425Z"},"trusted":true},"execution_count":30,"outputs":[{"name":"stdout","text":"Epoch 7/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.7746 - loss: 0.4688 - val_accuracy: 0.8117 - val_loss: 0.4506\nEpoch 8/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7768 - loss: 0.4602 - val_accuracy: 0.8052 - val_loss: 0.4495\nEpoch 9/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7948 - loss: 0.4369 - val_accuracy: 0.8117 - val_loss: 0.4482\nEpoch 10/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7973 - loss: 0.4314 - val_accuracy: 0.8182 - val_loss: 0.4474\nEpoch 11/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8035 - loss: 0.4183 - val_accuracy: 0.8182 - val_loss: 0.4471\nEpoch 12/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7598 - loss: 0.4607 - val_accuracy: 0.8117 - val_loss: 0.4465\nEpoch 13/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7736 - loss: 0.4414 - val_accuracy: 0.8117 - val_loss: 0.4466\nEpoch 14/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7924 - loss: 0.4557 - val_accuracy: 0.8052 - val_loss: 0.4461\nEpoch 15/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7908 - loss: 0.4297 - val_accuracy: 0.7987 - val_loss: 0.4456\nEpoch 16/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7732 - loss: 0.4551 - val_accuracy: 0.7987 - val_loss: 0.4451\nEpoch 17/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7648 - loss: 0.4571 - val_accuracy: 0.8052 - val_loss: 0.4458\nEpoch 18/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7629 - loss: 0.4726 - val_accuracy: 0.8052 - val_loss: 0.4457\nEpoch 19/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7682 - loss: 0.4658 - val_accuracy: 0.8052 - val_loss: 0.4459\nEpoch 20/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7589 - loss: 0.4771 - val_accuracy: 0.8052 - val_loss: 0.4455\nEpoch 21/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7962 - loss: 0.4298 - val_accuracy: 0.8052 - val_loss: 0.4463\nEpoch 22/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7588 - loss: 0.4738 - val_accuracy: 0.8052 - val_loss: 0.4462\nEpoch 23/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7815 - loss: 0.4297 - val_accuracy: 0.8052 - val_loss: 0.4459\nEpoch 24/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7721 - loss: 0.4545 - val_accuracy: 0.8052 - val_loss: 0.4461\nEpoch 25/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7727 - loss: 0.4401 - val_accuracy: 0.8117 - val_loss: 0.4457\nEpoch 26/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7999 - loss: 0.4134 - val_accuracy: 0.8117 - val_loss: 0.4457\nEpoch 27/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7770 - loss: 0.4469 - val_accuracy: 0.8052 - val_loss: 0.4465\nEpoch 28/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7808 - loss: 0.4285 - val_accuracy: 0.8182 - val_loss: 0.4464\nEpoch 29/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7672 - loss: 0.4616 - val_accuracy: 0.8052 - val_loss: 0.4465\nEpoch 30/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7670 - loss: 0.4577 - val_accuracy: 0.8052 - val_loss: 0.4470\nEpoch 31/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7907 - loss: 0.4235 - val_accuracy: 0.8052 - val_loss: 0.4472\nEpoch 32/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8023 - loss: 0.4170 - val_accuracy: 0.8052 - val_loss: 0.4474\nEpoch 33/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7651 - loss: 0.4593 - val_accuracy: 0.8052 - val_loss: 0.4480\nEpoch 34/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7666 - loss: 0.4417 - val_accuracy: 0.8182 - val_loss: 0.4477\nEpoch 35/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7940 - loss: 0.4131 - val_accuracy: 0.8182 - val_loss: 0.4477\nEpoch 36/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7563 - loss: 0.4490 - val_accuracy: 0.8117 - val_loss: 0.4476\nEpoch 37/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7823 - loss: 0.4179 - val_accuracy: 0.8182 - val_loss: 0.4468\nEpoch 38/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7939 - loss: 0.4211 - val_accuracy: 0.8117 - val_loss: 0.4470\nEpoch 39/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7912 - loss: 0.4226 - val_accuracy: 0.8117 - val_loss: 0.4475\nEpoch 40/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7876 - loss: 0.4311 - val_accuracy: 0.8247 - val_loss: 0.4476\nEpoch 41/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7876 - loss: 0.4142 - val_accuracy: 0.8182 - val_loss: 0.4478\nEpoch 42/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7790 - loss: 0.4318 - val_accuracy: 0.8247 - val_loss: 0.4475\nEpoch 43/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7678 - loss: 0.4259 - val_accuracy: 0.8117 - val_loss: 0.4477\nEpoch 44/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7734 - loss: 0.4269 - val_accuracy: 0.8117 - val_loss: 0.4484\nEpoch 45/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7861 - loss: 0.4201 - val_accuracy: 0.8052 - val_loss: 0.4493\nEpoch 46/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7537 - loss: 0.4580 - val_accuracy: 0.8052 - val_loss: 0.4492\nEpoch 47/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7728 - loss: 0.4238 - val_accuracy: 0.8052 - val_loss: 0.4496\nEpoch 48/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7994 - loss: 0.4037 - val_accuracy: 0.8117 - val_loss: 0.4489\nEpoch 49/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7777 - loss: 0.4404 - val_accuracy: 0.7987 - val_loss: 0.4492\nEpoch 50/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7915 - loss: 0.4201 - val_accuracy: 0.8117 - val_loss: 0.4487\nEpoch 51/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7802 - loss: 0.4063 - val_accuracy: 0.8117 - val_loss: 0.4491\nEpoch 52/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7809 - loss: 0.4189 - val_accuracy: 0.8182 - val_loss: 0.4486\nEpoch 53/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7955 - loss: 0.4248 - val_accuracy: 0.8117 - val_loss: 0.4494\nEpoch 54/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7649 - loss: 0.4219 - val_accuracy: 0.8117 - val_loss: 0.4488\nEpoch 55/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7659 - loss: 0.4299 - val_accuracy: 0.8117 - val_loss: 0.4485\nEpoch 56/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7514 - loss: 0.4699 - val_accuracy: 0.8182 - val_loss: 0.4486\nEpoch 57/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8069 - loss: 0.4150 - val_accuracy: 0.8182 - val_loss: 0.4488\nEpoch 58/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7564 - loss: 0.4526 - val_accuracy: 0.8182 - val_loss: 0.4492\nEpoch 59/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7709 - loss: 0.4360 - val_accuracy: 0.8182 - val_loss: 0.4494\nEpoch 60/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7776 - loss: 0.4262 - val_accuracy: 0.8182 - val_loss: 0.4487\nEpoch 61/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7834 - loss: 0.4202 - val_accuracy: 0.8117 - val_loss: 0.4483\nEpoch 62/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8054 - loss: 0.4020 - val_accuracy: 0.8052 - val_loss: 0.4494\nEpoch 63/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7813 - loss: 0.4091 - val_accuracy: 0.8052 - val_loss: 0.4487\nEpoch 64/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7625 - loss: 0.4456 - val_accuracy: 0.8182 - val_loss: 0.4486\nEpoch 65/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7926 - loss: 0.4201 - val_accuracy: 0.8247 - val_loss: 0.4480\nEpoch 66/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7811 - loss: 0.4251 - val_accuracy: 0.8247 - val_loss: 0.4481\nEpoch 67/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8017 - loss: 0.4120 - val_accuracy: 0.8247 - val_loss: 0.4484\nEpoch 68/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7989 - loss: 0.4188 - val_accuracy: 0.8247 - val_loss: 0.4489\nEpoch 69/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7987 - loss: 0.4274 - val_accuracy: 0.8182 - val_loss: 0.4497\nEpoch 70/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7519 - loss: 0.4576 - val_accuracy: 0.8182 - val_loss: 0.4495\nEpoch 71/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7701 - loss: 0.4273 - val_accuracy: 0.8182 - val_loss: 0.4498\nEpoch 72/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7661 - loss: 0.4490 - val_accuracy: 0.8247 - val_loss: 0.4498\nEpoch 73/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7787 - loss: 0.4043 - val_accuracy: 0.8117 - val_loss: 0.4495\nEpoch 74/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7537 - loss: 0.4525 - val_accuracy: 0.8182 - val_loss: 0.4489\nEpoch 75/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7920 - loss: 0.4077 - val_accuracy: 0.8052 - val_loss: 0.4494\nEpoch 76/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7785 - loss: 0.4362 - val_accuracy: 0.8182 - val_loss: 0.4488\nEpoch 77/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7736 - loss: 0.4417 - val_accuracy: 0.8117 - val_loss: 0.4482\nEpoch 78/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7673 - loss: 0.4437 - val_accuracy: 0.8182 - val_loss: 0.4478\nEpoch 79/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7897 - loss: 0.4265 - val_accuracy: 0.8182 - val_loss: 0.4487\nEpoch 80/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7838 - loss: 0.4225 - val_accuracy: 0.8182 - val_loss: 0.4483\nEpoch 81/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7969 - loss: 0.4079 - val_accuracy: 0.8117 - val_loss: 0.4485\nEpoch 82/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7932 - loss: 0.4166 - val_accuracy: 0.8117 - val_loss: 0.4481\nEpoch 83/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7893 - loss: 0.4147 - val_accuracy: 0.8182 - val_loss: 0.4478\nEpoch 84/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7893 - loss: 0.4110 - val_accuracy: 0.8182 - val_loss: 0.4477\nEpoch 85/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7886 - loss: 0.4251 - val_accuracy: 0.8247 - val_loss: 0.4489\nEpoch 86/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7921 - loss: 0.4218 - val_accuracy: 0.8182 - val_loss: 0.4489\nEpoch 87/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8113 - loss: 0.3957 - val_accuracy: 0.8117 - val_loss: 0.4497\nEpoch 88/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7981 - loss: 0.3971 - val_accuracy: 0.8117 - val_loss: 0.4502\nEpoch 89/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7743 - loss: 0.4440 - val_accuracy: 0.8117 - val_loss: 0.4509\nEpoch 90/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7970 - loss: 0.4124 - val_accuracy: 0.8117 - val_loss: 0.4509\nEpoch 91/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7746 - loss: 0.4345 - val_accuracy: 0.8117 - val_loss: 0.4503\nEpoch 92/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8036 - loss: 0.4321 - val_accuracy: 0.8117 - val_loss: 0.4503\nEpoch 93/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8011 - loss: 0.4155 - val_accuracy: 0.8182 - val_loss: 0.4501\nEpoch 94/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8127 - loss: 0.4179 - val_accuracy: 0.8182 - val_loss: 0.4494\nEpoch 95/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7938 - loss: 0.4147 - val_accuracy: 0.8117 - val_loss: 0.4491\nEpoch 96/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8213 - loss: 0.4038 - val_accuracy: 0.8247 - val_loss: 0.4485\nEpoch 97/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7824 - loss: 0.4138 - val_accuracy: 0.8117 - val_loss: 0.4487\nEpoch 98/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7947 - loss: 0.4384 - val_accuracy: 0.8117 - val_loss: 0.4498\nEpoch 99/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8031 - loss: 0.4242 - val_accuracy: 0.8117 - val_loss: 0.4495\nEpoch 100/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8120 - loss: 0.3982 - val_accuracy: 0.8117 - val_loss: 0.4497\n","output_type":"stream"},{"execution_count":30,"output_type":"execute_result","data":{"text/plain":"<keras.src.callbacks.history.History at 0x7d25795e0310>"},"metadata":{}}]},{"cell_type":"code","source":"def build_model(hp):\n    model = Sequential()\n    \n    # Number of units in the first Dense layer, tunable between 8 and 128 with step 8\n    units = hp.Int('units',  min_value=8, max_value=128, step=8)\n    model.add(Dense(units=units, activation='relu', input_dim=8))\n    \n    # Output layer\n    model.add(Dense(1, activation='sigmoid'))\n    \n    # Optimizer selection\n    optimizer = hp.Choice('optimizer', values=['adam', 'sgd', 'rmsprop', 'adadelta'])\n    \n    \n    model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])\n    \n    return model\n\n# Initialize the tuner\ntuner = kt.RandomSearch(\n    build_model,\n    objective='val_accuracy',\n    max_trials=5,\n    directory='mydir',\n    project_name='Work'\n)\n\n\n","metadata":{"execution":{"iopub.status.busy":"2024-07-20T07:23:04.181382Z","iopub.execute_input":"2024-07-20T07:23:04.181790Z","iopub.status.idle":"2024-07-20T07:23:04.219784Z","shell.execute_reply.started":"2024-07-20T07:23:04.181761Z","shell.execute_reply":"2024-07-20T07:23:04.218464Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"# Assuming you have training and validation data ready\n# X_train, y_train, X_val, y_val\n\n# Perform the search\ntuner.search(\n    X_train, Y_train,  # Training data\n    epochs=10,         # Number of epochs to train each model\n    validation_data=(X_test, Y_test)  # Validation data\n)\n","metadata":{"execution":{"iopub.status.busy":"2024-07-20T07:23:45.246711Z","iopub.execute_input":"2024-07-20T07:23:45.247191Z","iopub.status.idle":"2024-07-20T07:24:00.712505Z","shell.execute_reply.started":"2024-07-20T07:23:45.247155Z","shell.execute_reply":"2024-07-20T07:24:00.711325Z"},"trusted":true},"execution_count":39,"outputs":[{"name":"stdout","text":"Trial 5 Complete [00h 00m 03s]\nval_accuracy: 0.8246753215789795\n\nBest val_accuracy So Far: 0.8246753215789795\nTotal elapsed time: 00h 00m 15s\n","output_type":"stream"}]},{"cell_type":"code","source":"tuner.get_best_hyperparameters()[0].values","metadata":{"execution":{"iopub.status.busy":"2024-07-20T07:25:18.529451Z","iopub.execute_input":"2024-07-20T07:25:18.530530Z","iopub.status.idle":"2024-07-20T07:25:18.537759Z","shell.execute_reply.started":"2024-07-20T07:25:18.530472Z","shell.execute_reply":"2024-07-20T07:25:18.536577Z"},"trusted":true},"execution_count":41,"outputs":[{"execution_count":41,"output_type":"execute_result","data":{"text/plain":"{'units': 16, 'optimizer': 'sgd'}"},"metadata":{}}]},{"cell_type":"code","source":"model = tuner.get_best_models(num_models=1)[0]","metadata":{"execution":{"iopub.status.busy":"2024-07-20T07:26:39.424223Z","iopub.execute_input":"2024-07-20T07:26:39.424652Z","iopub.status.idle":"2024-07-20T07:26:40.642384Z","shell.execute_reply.started":"2024-07-20T07:26:39.424618Z","shell.execute_reply":"2024-07-20T07:26:40.641238Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"code","source":"model.fit(\n    X_train,         # Replace with your training data\n    Y_train,         # Replace with your training labels\n    batch_size=32,   # Number of samples per gradient update\n    epochs=100,      # Number of epochs to train the model\n    initial_epoch=6 \n)\n","metadata":{"execution":{"iopub.status.busy":"2024-07-20T07:27:47.718320Z","iopub.execute_input":"2024-07-20T07:27:47.719213Z","iopub.status.idle":"2024-07-20T07:27:53.931550Z","shell.execute_reply.started":"2024-07-20T07:27:47.719172Z","shell.execute_reply":"2024-07-20T07:27:53.930431Z"},"trusted":true},"execution_count":44,"outputs":[{"name":"stdout","text":"Epoch 7/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7517 - loss: 0.5029   \nEpoch 8/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7648 - loss: 0.4923 \nEpoch 9/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7597 - loss: 0.4780 \nEpoch 10/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7676 - loss: 0.4779 \nEpoch 11/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7484 - loss: 0.5093 \nEpoch 12/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7507 - loss: 0.4871 \nEpoch 13/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7703 - loss: 0.4706 \nEpoch 14/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7481 - loss: 0.4825 \nEpoch 15/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7664 - loss: 0.4609 \nEpoch 16/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7704 - loss: 0.4591 \nEpoch 17/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7753 - loss: 0.4637 \nEpoch 18/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7839 - loss: 0.4604 \nEpoch 19/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7696 - loss: 0.4663 \nEpoch 20/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7892 - loss: 0.4416 \nEpoch 21/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7515 - loss: 0.4817 \nEpoch 22/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7659 - loss: 0.4740 \nEpoch 23/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7728 - loss: 0.4462 \nEpoch 24/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7597 - loss: 0.4605 \nEpoch 25/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7729 - loss: 0.4519 \nEpoch 26/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7914 - loss: 0.4223 \nEpoch 27/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7632 - loss: 0.4729 \nEpoch 28/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7575 - loss: 0.4724 \nEpoch 29/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7870 - loss: 0.4480 \nEpoch 30/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7536 - loss: 0.4787 \nEpoch 31/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7465 - loss: 0.4674 \nEpoch 32/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7782 - loss: 0.4368 \nEpoch 33/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7901 - loss: 0.4213 \nEpoch 34/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7817 - loss: 0.4611 \nEpoch 35/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7981 - loss: 0.4257 \nEpoch 36/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7971 - loss: 0.4180 \nEpoch 37/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7886 - loss: 0.4219 \nEpoch 38/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7845 - loss: 0.4453 \nEpoch 39/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7561 - loss: 0.4697 \nEpoch 40/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7880 - loss: 0.4283 \nEpoch 41/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7676 - loss: 0.4524 \nEpoch 42/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7668 - loss: 0.4625 \nEpoch 43/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7609 - loss: 0.4527 \nEpoch 44/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7766 - loss: 0.4440 \nEpoch 45/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7933 - loss: 0.4192 \nEpoch 46/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7854 - loss: 0.4233 \nEpoch 47/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7873 - loss: 0.4300 \nEpoch 48/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7729 - loss: 0.4388 \nEpoch 49/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7739 - loss: 0.4444 \nEpoch 50/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7957 - loss: 0.4310 \nEpoch 51/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7603 - loss: 0.4471 \nEpoch 52/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7950 - loss: 0.4373 \nEpoch 53/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7811 - loss: 0.4182 \nEpoch 54/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7941 - loss: 0.4335 \nEpoch 55/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7894 - loss: 0.4152 \nEpoch 56/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7658 - loss: 0.4458 \nEpoch 57/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7754 - loss: 0.4617 \nEpoch 58/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7808 - loss: 0.4369 \nEpoch 59/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7939 - loss: 0.4298 \nEpoch 60/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7715 - loss: 0.4414 \nEpoch 61/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8021 - loss: 0.4050 \nEpoch 62/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7722 - loss: 0.4648 \nEpoch 63/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7743 - loss: 0.4421 \nEpoch 64/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8023 - loss: 0.4135 \nEpoch 65/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7939 - loss: 0.4104 \nEpoch 66/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8009 - loss: 0.4184 \nEpoch 67/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7711 - loss: 0.4350 \nEpoch 68/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7990 - loss: 0.4267 \nEpoch 69/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7967 - loss: 0.4183 \nEpoch 70/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7706 - loss: 0.4356 \nEpoch 71/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7632 - loss: 0.4571 \nEpoch 72/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7815 - loss: 0.4331 \nEpoch 73/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7769 - loss: 0.4352 \nEpoch 74/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7988 - loss: 0.3973 \nEpoch 75/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8077 - loss: 0.4057 \nEpoch 76/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7927 - loss: 0.4299 \nEpoch 77/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7900 - loss: 0.4427 \nEpoch 78/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7761 - loss: 0.4370 \nEpoch 79/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7765 - loss: 0.4067 \nEpoch 80/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7586 - loss: 0.4684 \nEpoch 81/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7976 - loss: 0.4138 \nEpoch 82/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7971 - loss: 0.4264 \nEpoch 83/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7630 - loss: 0.4423 \nEpoch 84/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7745 - loss: 0.4224 \nEpoch 85/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7721 - loss: 0.4358 \nEpoch 86/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7844 - loss: 0.4186 \nEpoch 87/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8077 - loss: 0.3923 \nEpoch 88/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7758 - loss: 0.4247 \nEpoch 89/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7855 - loss: 0.4482 \nEpoch 90/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7850 - loss: 0.4373 \nEpoch 91/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7839 - loss: 0.4386 \nEpoch 92/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7968 - loss: 0.4240 \nEpoch 93/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7979 - loss: 0.4349 \nEpoch 94/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7834 - loss: 0.4422 \nEpoch 95/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8033 - loss: 0.4252 \nEpoch 96/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7961 - loss: 0.4008 \nEpoch 97/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7925 - loss: 0.4229 \nEpoch 98/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7827 - loss: 0.4254 \nEpoch 99/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7978 - loss: 0.4399 \nEpoch 100/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7926 - loss: 0.4293 \n","output_type":"stream"},{"execution_count":44,"output_type":"execute_result","data":{"text/plain":"<keras.src.callbacks.history.History at 0x7d253b77a380>"},"metadata":{}}]},{"cell_type":"code","source":"def build_model(hp):\n    model = Sequential()\n    \n    # Number of units in the first Dense layer, tunable between 8 and 128 with step 8\n    units = hp.Int('units', min_value=8, max_value=128, step=8)\n    \n    # Number of layers, tunable between 1 and 5\n    num_layers = hp.Int('num_layers', min_value=1, max_value=5)\n    \n    # Input layer\n    model.add(Dense(units=units, activation='relu', input_dim=8))\n    \n    # Add the remaining layers\n    for _ in range(num_layers - 1):  # Adjust number of layers\n        model.add(Dense(units=units, activation='relu'))\n    \n    # Output layer\n    model.add(Dense(1, activation='sigmoid'))\n    \n    # Optimizer selection\n    optimizer = hp.Choice('optimizer', values=['adam', 'sgd', 'rmsprop', 'adadelta'])\n    \n    model.compile(\n        optimizer=optimizer,\n        loss='binary_crossentropy',\n        metrics=['accuracy']\n    )\n    \n    return model\n","metadata":{"execution":{"iopub.status.busy":"2024-07-20T07:47:35.446669Z","iopub.execute_input":"2024-07-20T07:47:35.447682Z","iopub.status.idle":"2024-07-20T07:47:35.456479Z","shell.execute_reply.started":"2024-07-20T07:47:35.447636Z","shell.execute_reply":"2024-07-20T07:47:35.455009Z"},"trusted":true},"execution_count":72,"outputs":[]},{"cell_type":"code","source":"# Initialize the tuner\ntuner = kt.RandomSearch(\n    build_model,\n    objective='val_accuracy',\n    max_trials=5,\n    directory='mydir',\n    project_name='Work'\n)\n","metadata":{"execution":{"iopub.status.busy":"2024-07-20T07:47:36.380062Z","iopub.execute_input":"2024-07-20T07:47:36.380490Z","iopub.status.idle":"2024-07-20T07:47:36.404984Z","shell.execute_reply.started":"2024-07-20T07:47:36.380457Z","shell.execute_reply":"2024-07-20T07:47:36.403608Z"},"trusted":true},"execution_count":73,"outputs":[{"name":"stdout","text":"Reloading Tuner from mydir/Work/tuner0.json\n","output_type":"stream"}]},{"cell_type":"code","source":"\n# Search for the best hyperparameters\ntuner.search(X_train, Y_train, epochs=10, validation_data=(X_test, Y_test))\n\n\n","metadata":{"execution":{"iopub.status.busy":"2024-07-20T07:47:37.483385Z","iopub.execute_input":"2024-07-20T07:47:37.483823Z","iopub.status.idle":"2024-07-20T07:47:37.489341Z","shell.execute_reply.started":"2024-07-20T07:47:37.483788Z","shell.execute_reply":"2024-07-20T07:47:37.488154Z"},"trusted":true},"execution_count":74,"outputs":[]},{"cell_type":"code","source":" tuner.get_best_hyperparameters()[0].values\n","metadata":{"execution":{"iopub.status.busy":"2024-07-20T07:47:38.736590Z","iopub.execute_input":"2024-07-20T07:47:38.736988Z","iopub.status.idle":"2024-07-20T07:47:38.744415Z","shell.execute_reply.started":"2024-07-20T07:47:38.736954Z","shell.execute_reply":"2024-07-20T07:47:38.743254Z"},"trusted":true},"execution_count":75,"outputs":[{"execution_count":75,"output_type":"execute_result","data":{"text/plain":"{'units': 16, 'optimizer': 'sgd'}"},"metadata":{}}]},{"cell_type":"code","source":"# Get the best model\nmodel = tuner.get_best_models(num_models=1)[0]\n\n","metadata":{"execution":{"iopub.status.busy":"2024-07-20T07:47:45.628948Z","iopub.execute_input":"2024-07-20T07:47:45.630064Z","iopub.status.idle":"2024-07-20T07:47:46.888659Z","shell.execute_reply.started":"2024-07-20T07:47:45.630020Z","shell.execute_reply":"2024-07-20T07:47:46.887412Z"},"trusted":true},"execution_count":77,"outputs":[]},{"cell_type":"code","source":"model.fit(X_train,Y_train,epochs=100,initial_epoch=6,validation_data=(X_test,Y_test))","metadata":{"execution":{"iopub.status.busy":"2024-07-20T07:49:18.236672Z","iopub.execute_input":"2024-07-20T07:49:18.237113Z","iopub.status.idle":"2024-07-20T07:49:26.848597Z","shell.execute_reply.started":"2024-07-20T07:49:18.237064Z","shell.execute_reply":"2024-07-20T07:49:26.847189Z"},"trusted":true},"execution_count":79,"outputs":[{"name":"stdout","text":"Epoch 7/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7508 - loss: 0.5005 - val_accuracy: 0.8052 - val_loss: 0.5244\nEpoch 8/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7619 - loss: 0.4939 - val_accuracy: 0.7987 - val_loss: 0.5229\nEpoch 9/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7432 - loss: 0.5103 - val_accuracy: 0.8052 - val_loss: 0.5217\nEpoch 10/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7486 - loss: 0.4993 - val_accuracy: 0.7987 - val_loss: 0.5204\nEpoch 11/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7362 - loss: 0.5118 - val_accuracy: 0.7922 - val_loss: 0.5197\nEpoch 12/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7659 - loss: 0.4965 - val_accuracy: 0.7922 - val_loss: 0.5186\nEpoch 13/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7473 - loss: 0.4968 - val_accuracy: 0.7922 - val_loss: 0.5174\nEpoch 14/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7441 - loss: 0.4985 - val_accuracy: 0.7922 - val_loss: 0.5168\nEpoch 15/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7307 - loss: 0.5037 - val_accuracy: 0.7857 - val_loss: 0.5162\nEpoch 16/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7517 - loss: 0.5074 - val_accuracy: 0.7857 - val_loss: 0.5153\nEpoch 17/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7496 - loss: 0.5008 - val_accuracy: 0.7857 - val_loss: 0.5146\nEpoch 18/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7542 - loss: 0.5023 - val_accuracy: 0.7857 - val_loss: 0.5139\nEpoch 19/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7403 - loss: 0.4872 - val_accuracy: 0.7792 - val_loss: 0.5137\nEpoch 20/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7627 - loss: 0.4929 - val_accuracy: 0.7792 - val_loss: 0.5133\nEpoch 21/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7450 - loss: 0.4897 - val_accuracy: 0.7922 - val_loss: 0.5123\nEpoch 22/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7908 - loss: 0.4683 - val_accuracy: 0.7922 - val_loss: 0.5116\nEpoch 23/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7615 - loss: 0.4961 - val_accuracy: 0.7987 - val_loss: 0.5107\nEpoch 24/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7734 - loss: 0.4739 - val_accuracy: 0.7987 - val_loss: 0.5101\nEpoch 25/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7730 - loss: 0.4708 - val_accuracy: 0.7922 - val_loss: 0.5096\nEpoch 26/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7658 - loss: 0.4763 - val_accuracy: 0.7987 - val_loss: 0.5090\nEpoch 27/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7569 - loss: 0.4763 - val_accuracy: 0.7922 - val_loss: 0.5086\nEpoch 28/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7945 - loss: 0.4505 - val_accuracy: 0.7857 - val_loss: 0.5084\nEpoch 29/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7522 - loss: 0.4786 - val_accuracy: 0.7857 - val_loss: 0.5080\nEpoch 30/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7766 - loss: 0.4675 - val_accuracy: 0.7922 - val_loss: 0.5074\nEpoch 31/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7686 - loss: 0.4905 - val_accuracy: 0.7987 - val_loss: 0.5068\nEpoch 32/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7643 - loss: 0.4609 - val_accuracy: 0.7987 - val_loss: 0.5065\nEpoch 33/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7769 - loss: 0.4692 - val_accuracy: 0.7922 - val_loss: 0.5065\nEpoch 34/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7710 - loss: 0.4571 - val_accuracy: 0.7922 - val_loss: 0.5060\nEpoch 35/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7855 - loss: 0.4594 - val_accuracy: 0.7922 - val_loss: 0.5057\nEpoch 36/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7741 - loss: 0.4582 - val_accuracy: 0.7987 - val_loss: 0.5054\nEpoch 37/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7807 - loss: 0.4505 - val_accuracy: 0.7922 - val_loss: 0.5049\nEpoch 38/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7746 - loss: 0.4560 - val_accuracy: 0.7922 - val_loss: 0.5046\nEpoch 39/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7814 - loss: 0.4500 - val_accuracy: 0.7922 - val_loss: 0.5044\nEpoch 40/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7722 - loss: 0.4593 - val_accuracy: 0.7922 - val_loss: 0.5042\nEpoch 41/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7722 - loss: 0.4436 - val_accuracy: 0.7922 - val_loss: 0.5040\nEpoch 42/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7816 - loss: 0.4593 - val_accuracy: 0.7922 - val_loss: 0.5040\nEpoch 43/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7641 - loss: 0.4842 - val_accuracy: 0.7987 - val_loss: 0.5036\nEpoch 44/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7566 - loss: 0.4806 - val_accuracy: 0.7922 - val_loss: 0.5033\nEpoch 45/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7714 - loss: 0.4432 - val_accuracy: 0.7922 - val_loss: 0.5033\nEpoch 46/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7674 - loss: 0.4733 - val_accuracy: 0.7987 - val_loss: 0.5033\nEpoch 47/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7568 - loss: 0.4708 - val_accuracy: 0.7987 - val_loss: 0.5031\nEpoch 48/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7617 - loss: 0.4649 - val_accuracy: 0.7987 - val_loss: 0.5026\nEpoch 49/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7592 - loss: 0.4795 - val_accuracy: 0.7987 - val_loss: 0.5026\nEpoch 50/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7670 - loss: 0.4614 - val_accuracy: 0.7987 - val_loss: 0.5025\nEpoch 51/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7534 - loss: 0.4827 - val_accuracy: 0.7922 - val_loss: 0.5023\nEpoch 52/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7756 - loss: 0.4500 - val_accuracy: 0.7987 - val_loss: 0.5021\nEpoch 53/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7921 - loss: 0.4429 - val_accuracy: 0.7987 - val_loss: 0.5021\nEpoch 54/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7805 - loss: 0.4390 - val_accuracy: 0.7987 - val_loss: 0.5020\nEpoch 55/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7924 - loss: 0.4468 - val_accuracy: 0.7987 - val_loss: 0.5020\nEpoch 56/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7500 - loss: 0.4897 - val_accuracy: 0.7987 - val_loss: 0.5020\nEpoch 57/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7521 - loss: 0.4938 - val_accuracy: 0.7987 - val_loss: 0.5021\nEpoch 58/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7621 - loss: 0.4774 - val_accuracy: 0.7987 - val_loss: 0.5020\nEpoch 59/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7905 - loss: 0.4552 - val_accuracy: 0.7987 - val_loss: 0.5018\nEpoch 60/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7859 - loss: 0.4498 - val_accuracy: 0.7987 - val_loss: 0.5015\nEpoch 61/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7726 - loss: 0.4504 - val_accuracy: 0.7987 - val_loss: 0.5012\nEpoch 62/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7636 - loss: 0.4788 - val_accuracy: 0.7987 - val_loss: 0.5013\nEpoch 63/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7881 - loss: 0.4467 - val_accuracy: 0.7987 - val_loss: 0.5009\nEpoch 64/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7929 - loss: 0.4150 - val_accuracy: 0.7987 - val_loss: 0.5005\nEpoch 65/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7622 - loss: 0.4771 - val_accuracy: 0.7987 - val_loss: 0.5003\nEpoch 66/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7692 - loss: 0.4612 - val_accuracy: 0.7987 - val_loss: 0.5004\nEpoch 67/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8027 - loss: 0.4435 - val_accuracy: 0.7987 - val_loss: 0.5006\nEpoch 68/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7672 - loss: 0.4715 - val_accuracy: 0.7987 - val_loss: 0.5007\nEpoch 69/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7892 - loss: 0.4345 - val_accuracy: 0.7987 - val_loss: 0.5010\nEpoch 70/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7814 - loss: 0.4276 - val_accuracy: 0.7987 - val_loss: 0.5008\nEpoch 71/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7501 - loss: 0.4719 - val_accuracy: 0.7987 - val_loss: 0.5006\nEpoch 72/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7706 - loss: 0.4809 - val_accuracy: 0.7987 - val_loss: 0.5004\nEpoch 73/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7878 - loss: 0.4336 - val_accuracy: 0.7987 - val_loss: 0.5003\nEpoch 74/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7973 - loss: 0.4266 - val_accuracy: 0.7987 - val_loss: 0.5003\nEpoch 75/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7734 - loss: 0.4620 - val_accuracy: 0.7987 - val_loss: 0.5003\nEpoch 76/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7997 - loss: 0.4331 - val_accuracy: 0.7987 - val_loss: 0.5002\nEpoch 77/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7706 - loss: 0.4458 - val_accuracy: 0.7987 - val_loss: 0.4996\nEpoch 78/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8108 - loss: 0.4256 - val_accuracy: 0.7987 - val_loss: 0.4997\nEpoch 79/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7782 - loss: 0.4664 - val_accuracy: 0.7987 - val_loss: 0.4994\nEpoch 80/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7795 - loss: 0.4438 - val_accuracy: 0.7987 - val_loss: 0.4993\nEpoch 81/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7546 - loss: 0.4701 - val_accuracy: 0.7987 - val_loss: 0.4992\nEpoch 82/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7820 - loss: 0.4513 - val_accuracy: 0.7987 - val_loss: 0.4991\nEpoch 83/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7897 - loss: 0.4408 - val_accuracy: 0.7987 - val_loss: 0.4994\nEpoch 84/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7969 - loss: 0.4415 - val_accuracy: 0.7987 - val_loss: 0.4989\nEpoch 85/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7864 - loss: 0.4379 - val_accuracy: 0.7987 - val_loss: 0.4990\nEpoch 86/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7779 - loss: 0.4457 - val_accuracy: 0.7987 - val_loss: 0.4989\nEpoch 87/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7929 - loss: 0.4474 - val_accuracy: 0.7987 - val_loss: 0.4988\nEpoch 88/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7831 - loss: 0.4622 - val_accuracy: 0.7987 - val_loss: 0.4985\nEpoch 89/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7830 - loss: 0.4369 - val_accuracy: 0.7987 - val_loss: 0.4984\nEpoch 90/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7712 - loss: 0.4555 - val_accuracy: 0.7987 - val_loss: 0.4984\nEpoch 91/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7652 - loss: 0.4590 - val_accuracy: 0.7987 - val_loss: 0.4981\nEpoch 92/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7684 - loss: 0.4583 - val_accuracy: 0.7922 - val_loss: 0.4979\nEpoch 93/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7868 - loss: 0.4387 - val_accuracy: 0.7922 - val_loss: 0.4979\nEpoch 94/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7557 - loss: 0.4614 - val_accuracy: 0.7987 - val_loss: 0.4977\nEpoch 95/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7853 - loss: 0.4309 - val_accuracy: 0.7987 - val_loss: 0.4977\nEpoch 96/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7877 - loss: 0.4436 - val_accuracy: 0.7987 - val_loss: 0.4974\nEpoch 97/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7787 - loss: 0.4517 - val_accuracy: 0.7857 - val_loss: 0.4978\nEpoch 98/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7689 - loss: 0.4316 - val_accuracy: 0.7987 - val_loss: 0.4973\nEpoch 99/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7861 - loss: 0.4242 - val_accuracy: 0.7987 - val_loss: 0.4971\nEpoch 100/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8006 - loss: 0.4267 - val_accuracy: 0.7987 - val_loss: 0.4972\n","output_type":"stream"},{"execution_count":79,"output_type":"execute_result","data":{"text/plain":"<keras.src.callbacks.history.History at 0x7d253b603820>"},"metadata":{}}]},{"cell_type":"code","source":"def build_model(hp):\n    model = Sequential()\n    counter = 0\n    \n    # Number of layers, tunable between 1 and 5\n    num_layers = hp.Int('num_layers', min_value=1, max_value=10)\n    \n    # Add layers\n    for i in range(num_layers):\n        if counter == 0:\n            # First layer with input_dim\n            model.add(Dense(\n                units=hp.Int('units' + str(i), min_value=8, max_value=128, step=8),\n                activation='relu',\n                input_dim=8\n            ))\n        else:\n            # Subsequent layers without input_dim\n            model.add(Dense(\n                units=hp.Int('units' + str(i), min_value=8, max_value=128, step=8),\n                activation='relu'\n            ))\n        counter += 1\n    \n    # Output layer\n    model.add(Dense(1, activation='sigmoid'))\n    \n    # Optimizer selection\n    optimizer = hp.Choice('optimizer', values=['adam', 'sgd', 'rmsprop', 'adadelta'])\n    \n    model.compile(\n        optimizer=optimizer,\n        loss='binary_crossentropy',\n        metrics=['accuracy']\n    )\n    \n    return model\n","metadata":{"execution":{"iopub.status.busy":"2024-07-20T07:52:36.671059Z","iopub.execute_input":"2024-07-20T07:52:36.671530Z","iopub.status.idle":"2024-07-20T07:52:36.681360Z","shell.execute_reply.started":"2024-07-20T07:52:36.671496Z","shell.execute_reply":"2024-07-20T07:52:36.679805Z"},"trusted":true},"execution_count":80,"outputs":[]},{"cell_type":"code","source":"tuner = kt.RandomSearch(\n    build_model,\n    objective='val_accuracy',\n    max_trials=10,\n    directory='my_dir',\n    project_name='Work'\n)\n","metadata":{"execution":{"iopub.status.busy":"2024-07-20T07:53:24.441017Z","iopub.execute_input":"2024-07-20T07:53:24.441465Z","iopub.status.idle":"2024-07-20T07:53:24.475481Z","shell.execute_reply.started":"2024-07-20T07:53:24.441432Z","shell.execute_reply":"2024-07-20T07:53:24.474304Z"},"trusted":true},"execution_count":83,"outputs":[]},{"cell_type":"code","source":"tuner.search(X_train, Y_train, epochs=5, validation_data=(X_test, Y_test))","metadata":{"execution":{"iopub.status.busy":"2024-07-20T07:54:56.994697Z","iopub.execute_input":"2024-07-20T07:54:56.995122Z","iopub.status.idle":"2024-07-20T07:55:33.181338Z","shell.execute_reply.started":"2024-07-20T07:54:56.995078Z","shell.execute_reply":"2024-07-20T07:55:33.180189Z"},"trusted":true},"execution_count":86,"outputs":[{"name":"stdout","text":"Trial 10 Complete [00h 00m 03s]\nval_accuracy: 0.649350643157959\n\nBest val_accuracy So Far: 0.8246753215789795\nTotal elapsed time: 00h 00m 36s\n","output_type":"stream"}]},{"cell_type":"code","source":"best_model = tuner.get_best_models(num_models=1)[0]","metadata":{"execution":{"iopub.status.busy":"2024-07-20T07:55:41.318238Z","iopub.execute_input":"2024-07-20T07:55:41.318651Z","iopub.status.idle":"2024-07-20T07:55:42.860425Z","shell.execute_reply.started":"2024-07-20T07:55:41.318620Z","shell.execute_reply":"2024-07-20T07:55:42.859193Z"},"trusted":true},"execution_count":88,"outputs":[]},{"cell_type":"code","source":"model.fit(X_train,Y_train,epochs=200,initial_epoch=6,validation_data=(X_test,Y_test))","metadata":{"execution":{"iopub.status.busy":"2024-07-20T07:57:50.315548Z","iopub.execute_input":"2024-07-20T07:57:50.316029Z","iopub.status.idle":"2024-07-20T07:58:08.288466Z","shell.execute_reply.started":"2024-07-20T07:57:50.315990Z","shell.execute_reply":"2024-07-20T07:58:08.287277Z"},"trusted":true},"execution_count":89,"outputs":[{"name":"stdout","text":"Epoch 7/200\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7580 - loss: 0.4744 - val_accuracy: 0.7987 - val_loss: 0.4969\nEpoch 8/200\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7502 - loss: 0.4798 - val_accuracy: 0.7922 - val_loss: 0.4970\nEpoch 9/200\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7834 - loss: 0.4372 - val_accuracy: 0.7922 - val_loss: 0.4970\nEpoch 10/200\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7721 - loss: 0.4444 - val_accuracy: 0.7987 - val_loss: 0.4970\nEpoch 11/200\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7776 - loss: 0.4390 - val_accuracy: 0.7922 - val_loss: 0.4971\nEpoch 12/200\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7731 - loss: 0.4493 - val_accuracy: 0.7922 - val_loss: 0.4969\nEpoch 13/200\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7670 - loss: 0.4505 - val_accuracy: 0.7922 - val_loss: 0.4968\nEpoch 14/200\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7544 - loss: 0.4758 - val_accuracy: 0.7922 - val_loss: 0.4967\nEpoch 15/200\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7660 - loss: 0.4718 - val_accuracy: 0.7857 - val_loss: 0.4967\nEpoch 16/200\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7808 - loss: 0.4444 - val_accuracy: 0.7857 - val_loss: 0.4968\nEpoch 17/200\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7818 - loss: 0.4395 - val_accuracy: 0.7857 - val_loss: 0.4970\nEpoch 18/200\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8146 - loss: 0.4043 - val_accuracy: 0.7857 - val_loss: 0.4973\nEpoch 19/200\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7607 - loss: 0.4759 - val_accuracy: 0.7857 - val_loss: 0.4971\nEpoch 20/200\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7767 - loss: 0.4629 - val_accuracy: 0.7922 - val_loss: 0.4970\nEpoch 21/200\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7667 - loss: 0.4658 - val_accuracy: 0.7922 - val_loss: 0.4969\nEpoch 22/200\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7852 - loss: 0.4472 - val_accuracy: 0.7922 - val_loss: 0.4968\nEpoch 23/200\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7853 - loss: 0.4284 - val_accuracy: 0.7922 - val_loss: 0.4966\nEpoch 24/200\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7703 - loss: 0.4480 - val_accuracy: 0.7922 - val_loss: 0.4966\nEpoch 25/200\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7502 - loss: 0.4715 - val_accuracy: 0.7857 - val_loss: 0.4967\nEpoch 26/200\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7834 - loss: 0.4339 - val_accuracy: 0.7857 - val_loss: 0.4964\nEpoch 27/200\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7856 - loss: 0.4329 - val_accuracy: 0.7857 - val_loss: 0.4964\nEpoch 28/200\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7813 - loss: 0.4644 - val_accuracy: 0.7857 - val_loss: 0.4964\nEpoch 29/200\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7799 - loss: 0.4584 - val_accuracy: 0.7857 - val_loss: 0.4961\nEpoch 30/200\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7920 - loss: 0.4263 - val_accuracy: 0.7857 - val_loss: 0.4958\nEpoch 31/200\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7751 - loss: 0.4212 - val_accuracy: 0.7857 - val_loss: 0.4958\nEpoch 32/200\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7777 - loss: 0.4210 - val_accuracy: 0.7857 - val_loss: 0.4958\nEpoch 33/200\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7569 - loss: 0.4569 - val_accuracy: 0.7857 - val_loss: 0.4957\nEpoch 34/200\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7711 - loss: 0.4203 - val_accuracy: 0.7857 - val_loss: 0.4955\nEpoch 35/200\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7429 - loss: 0.4683 - val_accuracy: 0.7857 - val_loss: 0.4950\nEpoch 36/200\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7448 - loss: 0.4792 - val_accuracy: 0.7857 - val_loss: 0.4948\nEpoch 37/200\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7932 - loss: 0.4311 - val_accuracy: 0.7857 - val_loss: 0.4949\nEpoch 38/200\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7704 - loss: 0.4418 - val_accuracy: 0.7857 - val_loss: 0.4946\nEpoch 39/200\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7553 - loss: 0.4658 - val_accuracy: 0.7857 - val_loss: 0.4946\nEpoch 40/200\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7874 - loss: 0.4274 - val_accuracy: 0.7792 - val_loss: 0.4944\nEpoch 41/200\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7664 - loss: 0.4337 - val_accuracy: 0.7792 - val_loss: 0.4942\nEpoch 42/200\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7520 - loss: 0.4639 - val_accuracy: 0.7792 - val_loss: 0.4941\nEpoch 43/200\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7770 - loss: 0.4610 - val_accuracy: 0.7792 - val_loss: 0.4941\nEpoch 44/200\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7793 - loss: 0.4338 - val_accuracy: 0.7792 - val_loss: 0.4940\nEpoch 45/200\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7760 - loss: 0.4357 - val_accuracy: 0.7792 - val_loss: 0.4941\nEpoch 46/200\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7853 - loss: 0.4262 - val_accuracy: 0.7792 - val_loss: 0.4940\nEpoch 47/200\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7812 - loss: 0.4363 - val_accuracy: 0.7792 - val_loss: 0.4939\nEpoch 48/200\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7783 - loss: 0.4475 - val_accuracy: 0.7792 - val_loss: 0.4937\nEpoch 49/200\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7647 - loss: 0.4703 - val_accuracy: 0.7792 - val_loss: 0.4936\nEpoch 50/200\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7708 - loss: 0.4495 - val_accuracy: 0.7792 - val_loss: 0.4934\nEpoch 51/200\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7672 - loss: 0.4865 - val_accuracy: 0.7792 - val_loss: 0.4924\nEpoch 52/200\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7572 - loss: 0.4383 - val_accuracy: 0.7792 - val_loss: 0.4927\nEpoch 53/200\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7520 - loss: 0.4667 - val_accuracy: 0.7792 - val_loss: 0.4927\nEpoch 54/200\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7738 - loss: 0.4284 - val_accuracy: 0.7792 - val_loss: 0.4931\nEpoch 55/200\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7803 - loss: 0.4236 - val_accuracy: 0.7792 - val_loss: 0.4930\nEpoch 56/200\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7707 - loss: 0.4410 - val_accuracy: 0.7792 - val_loss: 0.4926\nEpoch 57/200\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7707 - loss: 0.4353 - val_accuracy: 0.7792 - val_loss: 0.4923\nEpoch 58/200\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7975 - loss: 0.4182 - val_accuracy: 0.7792 - val_loss: 0.4923\nEpoch 59/200\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7576 - loss: 0.4583 - val_accuracy: 0.7792 - val_loss: 0.4922\nEpoch 60/200\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7635 - loss: 0.4576 - val_accuracy: 0.7792 - val_loss: 0.4925\nEpoch 61/200\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7612 - loss: 0.4410 - val_accuracy: 0.7792 - val_loss: 0.4926\nEpoch 62/200\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7812 - loss: 0.4382 - val_accuracy: 0.7792 - val_loss: 0.4926\nEpoch 63/200\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7491 - loss: 0.4592 - val_accuracy: 0.7792 - val_loss: 0.4924\nEpoch 64/200\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7752 - loss: 0.4514 - val_accuracy: 0.7792 - val_loss: 0.4916\nEpoch 65/200\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7706 - loss: 0.4459 - val_accuracy: 0.7792 - val_loss: 0.4917\nEpoch 66/200\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7799 - loss: 0.4292 - val_accuracy: 0.7792 - val_loss: 0.4913\nEpoch 67/200\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7568 - loss: 0.4562 - val_accuracy: 0.7792 - val_loss: 0.4915\nEpoch 68/200\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7603 - loss: 0.4459 - val_accuracy: 0.7792 - val_loss: 0.4911\nEpoch 69/200\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7834 - loss: 0.4183 - val_accuracy: 0.7792 - val_loss: 0.4908\nEpoch 70/200\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7792 - loss: 0.4311 - val_accuracy: 0.7792 - val_loss: 0.4910\nEpoch 71/200\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8008 - loss: 0.4315 - val_accuracy: 0.7792 - val_loss: 0.4910\nEpoch 72/200\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7730 - loss: 0.4531 - val_accuracy: 0.7792 - val_loss: 0.4913\nEpoch 73/200\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7761 - loss: 0.4245 - val_accuracy: 0.7792 - val_loss: 0.4909\nEpoch 74/200\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7755 - loss: 0.4265 - val_accuracy: 0.7792 - val_loss: 0.4906\nEpoch 75/200\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7908 - loss: 0.4293 - val_accuracy: 0.7792 - val_loss: 0.4906\nEpoch 76/200\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7729 - loss: 0.4523 - val_accuracy: 0.7792 - val_loss: 0.4904\nEpoch 77/200\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7795 - loss: 0.4371 - val_accuracy: 0.7792 - val_loss: 0.4903\nEpoch 78/200\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7746 - loss: 0.4533 - val_accuracy: 0.7792 - val_loss: 0.4900\nEpoch 79/200\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7739 - loss: 0.4591 - val_accuracy: 0.7792 - val_loss: 0.4899\nEpoch 80/200\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7898 - loss: 0.4246 - val_accuracy: 0.7792 - val_loss: 0.4901\nEpoch 81/200\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7621 - loss: 0.4586 - val_accuracy: 0.7792 - val_loss: 0.4900\nEpoch 82/200\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7919 - loss: 0.4245 - val_accuracy: 0.7792 - val_loss: 0.4902\nEpoch 83/200\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7912 - loss: 0.4309 - val_accuracy: 0.7792 - val_loss: 0.4904\nEpoch 84/200\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7765 - loss: 0.4506 - val_accuracy: 0.7792 - val_loss: 0.4902\nEpoch 85/200\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8020 - loss: 0.4083 - val_accuracy: 0.7792 - val_loss: 0.4904\nEpoch 86/200\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8050 - loss: 0.4055 - val_accuracy: 0.7792 - val_loss: 0.4903\nEpoch 87/200\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7965 - loss: 0.4326 - val_accuracy: 0.7792 - val_loss: 0.4905\nEpoch 88/200\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7925 - loss: 0.4228 - val_accuracy: 0.7792 - val_loss: 0.4905\nEpoch 89/200\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8004 - loss: 0.4108 - val_accuracy: 0.7792 - val_loss: 0.4902\nEpoch 90/200\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7849 - loss: 0.4437 - val_accuracy: 0.7792 - val_loss: 0.4903\nEpoch 91/200\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8268 - loss: 0.3858 - val_accuracy: 0.7792 - val_loss: 0.4904\nEpoch 92/200\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7873 - loss: 0.4331 - val_accuracy: 0.7727 - val_loss: 0.4903\nEpoch 93/200\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7942 - loss: 0.4110 - val_accuracy: 0.7792 - val_loss: 0.4903\nEpoch 94/200\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7548 - loss: 0.4769 - val_accuracy: 0.7727 - val_loss: 0.4907\nEpoch 95/200\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7562 - loss: 0.4466 - val_accuracy: 0.7727 - val_loss: 0.4907\nEpoch 96/200\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7913 - loss: 0.4191 - val_accuracy: 0.7727 - val_loss: 0.4908\nEpoch 97/200\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7704 - loss: 0.4504 - val_accuracy: 0.7727 - val_loss: 0.4907\nEpoch 98/200\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7876 - loss: 0.4385 - val_accuracy: 0.7727 - val_loss: 0.4903\nEpoch 99/200\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7969 - loss: 0.4265 - val_accuracy: 0.7727 - val_loss: 0.4903\nEpoch 100/200\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8034 - loss: 0.4348 - val_accuracy: 0.7727 - val_loss: 0.4902\nEpoch 101/200\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7711 - loss: 0.4372 - val_accuracy: 0.7727 - val_loss: 0.4905\nEpoch 102/200\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7566 - loss: 0.4787 - val_accuracy: 0.7727 - val_loss: 0.4903\nEpoch 103/200\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7818 - loss: 0.4483 - val_accuracy: 0.7727 - val_loss: 0.4898\nEpoch 104/200\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7684 - loss: 0.4766 - val_accuracy: 0.7727 - val_loss: 0.4898\nEpoch 105/200\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7943 - loss: 0.4373 - val_accuracy: 0.7727 - val_loss: 0.4898\nEpoch 106/200\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7777 - loss: 0.4301 - val_accuracy: 0.7727 - val_loss: 0.4901\nEpoch 107/200\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7905 - loss: 0.4139 - val_accuracy: 0.7662 - val_loss: 0.4903\nEpoch 108/200\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7925 - loss: 0.4193 - val_accuracy: 0.7662 - val_loss: 0.4905\nEpoch 109/200\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7936 - loss: 0.4400 - val_accuracy: 0.7662 - val_loss: 0.4899\nEpoch 110/200\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8022 - loss: 0.4242 - val_accuracy: 0.7727 - val_loss: 0.4900\nEpoch 111/200\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7981 - loss: 0.4388 - val_accuracy: 0.7727 - val_loss: 0.4901\nEpoch 112/200\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7944 - loss: 0.4277 - val_accuracy: 0.7662 - val_loss: 0.4904\nEpoch 113/200\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7920 - loss: 0.4235 - val_accuracy: 0.7727 - val_loss: 0.4903\nEpoch 114/200\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7771 - loss: 0.4590 - val_accuracy: 0.7662 - val_loss: 0.4903\nEpoch 115/200\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8059 - loss: 0.4178 - val_accuracy: 0.7727 - val_loss: 0.4897\nEpoch 116/200\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7861 - loss: 0.4516 - val_accuracy: 0.7727 - val_loss: 0.4895\nEpoch 117/200\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7722 - loss: 0.4548 - val_accuracy: 0.7727 - val_loss: 0.4895\nEpoch 118/200\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7764 - loss: 0.4548 - val_accuracy: 0.7727 - val_loss: 0.4895\nEpoch 119/200\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7728 - loss: 0.4498 - val_accuracy: 0.7727 - val_loss: 0.4898\nEpoch 120/200\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8044 - loss: 0.4095 - val_accuracy: 0.7727 - val_loss: 0.4896\nEpoch 121/200\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7844 - loss: 0.4323 - val_accuracy: 0.7727 - val_loss: 0.4895\nEpoch 122/200\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7848 - loss: 0.4351 - val_accuracy: 0.7727 - val_loss: 0.4897\nEpoch 123/200\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7833 - loss: 0.4319 - val_accuracy: 0.7727 - val_loss: 0.4899\nEpoch 124/200\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7791 - loss: 0.4327 - val_accuracy: 0.7727 - val_loss: 0.4900\nEpoch 125/200\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7931 - loss: 0.4212 - val_accuracy: 0.7727 - val_loss: 0.4898\nEpoch 126/200\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7678 - loss: 0.4405 - val_accuracy: 0.7727 - val_loss: 0.4896\nEpoch 127/200\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7812 - loss: 0.4399 - val_accuracy: 0.7662 - val_loss: 0.4893\nEpoch 128/200\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7932 - loss: 0.4300 - val_accuracy: 0.7727 - val_loss: 0.4894\nEpoch 129/200\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7685 - loss: 0.4392 - val_accuracy: 0.7727 - val_loss: 0.4894\nEpoch 130/200\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8074 - loss: 0.3942 - val_accuracy: 0.7727 - val_loss: 0.4893\nEpoch 131/200\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7928 - loss: 0.4381 - val_accuracy: 0.7662 - val_loss: 0.4894\nEpoch 132/200\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7733 - loss: 0.4353 - val_accuracy: 0.7727 - val_loss: 0.4892\nEpoch 133/200\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7721 - loss: 0.4537 - val_accuracy: 0.7727 - val_loss: 0.4891\nEpoch 134/200\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7912 - loss: 0.4215 - val_accuracy: 0.7792 - val_loss: 0.4887\nEpoch 135/200\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7840 - loss: 0.4174 - val_accuracy: 0.7792 - val_loss: 0.4886\nEpoch 136/200\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7773 - loss: 0.4358 - val_accuracy: 0.7727 - val_loss: 0.4884\nEpoch 137/200\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7762 - loss: 0.4199 - val_accuracy: 0.7662 - val_loss: 0.4886\nEpoch 138/200\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7753 - loss: 0.4208 - val_accuracy: 0.7662 - val_loss: 0.4885\nEpoch 139/200\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7830 - loss: 0.4361 - val_accuracy: 0.7662 - val_loss: 0.4887\nEpoch 140/200\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7499 - loss: 0.4673 - val_accuracy: 0.7662 - val_loss: 0.4882\nEpoch 141/200\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7777 - loss: 0.4565 - val_accuracy: 0.7662 - val_loss: 0.4884\nEpoch 142/200\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7926 - loss: 0.4286 - val_accuracy: 0.7662 - val_loss: 0.4886\nEpoch 143/200\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7826 - loss: 0.4509 - val_accuracy: 0.7662 - val_loss: 0.4884\nEpoch 144/200\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7817 - loss: 0.4278 - val_accuracy: 0.7662 - val_loss: 0.4880\nEpoch 145/200\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7747 - loss: 0.4349 - val_accuracy: 0.7662 - val_loss: 0.4881\nEpoch 146/200\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7921 - loss: 0.4026 - val_accuracy: 0.7662 - val_loss: 0.4885\nEpoch 147/200\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7742 - loss: 0.4451 - val_accuracy: 0.7662 - val_loss: 0.4886\nEpoch 148/200\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7999 - loss: 0.4118 - val_accuracy: 0.7662 - val_loss: 0.4886\nEpoch 149/200\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7620 - loss: 0.4740 - val_accuracy: 0.7662 - val_loss: 0.4887\nEpoch 150/200\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7736 - loss: 0.4433 - val_accuracy: 0.7662 - val_loss: 0.4888\nEpoch 151/200\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7776 - loss: 0.4472 - val_accuracy: 0.7662 - val_loss: 0.4888\nEpoch 152/200\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7912 - loss: 0.4456 - val_accuracy: 0.7662 - val_loss: 0.4887\nEpoch 153/200\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7869 - loss: 0.4502 - val_accuracy: 0.7662 - val_loss: 0.4890\nEpoch 154/200\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7516 - loss: 0.4571 - val_accuracy: 0.7662 - val_loss: 0.4886\nEpoch 155/200\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7938 - loss: 0.4333 - val_accuracy: 0.7662 - val_loss: 0.4884\nEpoch 156/200\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7853 - loss: 0.4406 - val_accuracy: 0.7662 - val_loss: 0.4884\nEpoch 157/200\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7904 - loss: 0.4283 - val_accuracy: 0.7662 - val_loss: 0.4884\nEpoch 158/200\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7649 - loss: 0.4617 - val_accuracy: 0.7662 - val_loss: 0.4883\nEpoch 159/200\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8038 - loss: 0.4143 - val_accuracy: 0.7662 - val_loss: 0.4880\nEpoch 160/200\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7901 - loss: 0.4336 - val_accuracy: 0.7662 - val_loss: 0.4877\nEpoch 161/200\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7836 - loss: 0.4319 - val_accuracy: 0.7662 - val_loss: 0.4879\nEpoch 162/200\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7744 - loss: 0.4273 - val_accuracy: 0.7662 - val_loss: 0.4881\nEpoch 163/200\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8101 - loss: 0.4087 - val_accuracy: 0.7662 - val_loss: 0.4877\nEpoch 164/200\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7811 - loss: 0.4277 - val_accuracy: 0.7662 - val_loss: 0.4881\nEpoch 165/200\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7991 - loss: 0.4343 - val_accuracy: 0.7662 - val_loss: 0.4882\nEpoch 166/200\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7772 - loss: 0.4293 - val_accuracy: 0.7662 - val_loss: 0.4879\nEpoch 167/200\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7729 - loss: 0.4515 - val_accuracy: 0.7662 - val_loss: 0.4881\nEpoch 168/200\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7783 - loss: 0.4512 - val_accuracy: 0.7662 - val_loss: 0.4881\nEpoch 169/200\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7529 - loss: 0.4745 - val_accuracy: 0.7662 - val_loss: 0.4880\nEpoch 170/200\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7924 - loss: 0.4105 - val_accuracy: 0.7662 - val_loss: 0.4881\nEpoch 171/200\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8016 - loss: 0.4168 - val_accuracy: 0.7662 - val_loss: 0.4881\nEpoch 172/200\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7900 - loss: 0.4257 - val_accuracy: 0.7662 - val_loss: 0.4879\nEpoch 173/200\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7934 - loss: 0.4320 - val_accuracy: 0.7662 - val_loss: 0.4884\nEpoch 174/200\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7860 - loss: 0.4379 - val_accuracy: 0.7662 - val_loss: 0.4882\nEpoch 175/200\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7745 - loss: 0.4191 - val_accuracy: 0.7662 - val_loss: 0.4880\nEpoch 176/200\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7988 - loss: 0.4182 - val_accuracy: 0.7662 - val_loss: 0.4878\nEpoch 177/200\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7974 - loss: 0.4174 - val_accuracy: 0.7662 - val_loss: 0.4877\nEpoch 178/200\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7910 - loss: 0.4309 - val_accuracy: 0.7727 - val_loss: 0.4876\nEpoch 179/200\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7965 - loss: 0.4244 - val_accuracy: 0.7662 - val_loss: 0.4875\nEpoch 180/200\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8100 - loss: 0.4169 - val_accuracy: 0.7662 - val_loss: 0.4869\nEpoch 181/200\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7998 - loss: 0.4434 - val_accuracy: 0.7662 - val_loss: 0.4869\nEpoch 182/200\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7764 - loss: 0.4500 - val_accuracy: 0.7662 - val_loss: 0.4869\nEpoch 183/200\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7560 - loss: 0.4695 - val_accuracy: 0.7662 - val_loss: 0.4865\nEpoch 184/200\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7711 - loss: 0.4468 - val_accuracy: 0.7662 - val_loss: 0.4866\nEpoch 185/200\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8060 - loss: 0.4193 - val_accuracy: 0.7662 - val_loss: 0.4864\nEpoch 186/200\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8119 - loss: 0.4236 - val_accuracy: 0.7662 - val_loss: 0.4866\nEpoch 187/200\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8039 - loss: 0.4318 - val_accuracy: 0.7727 - val_loss: 0.4862\nEpoch 188/200\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8067 - loss: 0.4316 - val_accuracy: 0.7727 - val_loss: 0.4863\nEpoch 189/200\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7638 - loss: 0.4635 - val_accuracy: 0.7727 - val_loss: 0.4863\nEpoch 190/200\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8191 - loss: 0.4125 - val_accuracy: 0.7727 - val_loss: 0.4860\nEpoch 191/200\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7874 - loss: 0.4346 - val_accuracy: 0.7727 - val_loss: 0.4859\nEpoch 192/200\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8063 - loss: 0.4271 - val_accuracy: 0.7727 - val_loss: 0.4855\nEpoch 193/200\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7830 - loss: 0.4375 - val_accuracy: 0.7727 - val_loss: 0.4855\nEpoch 194/200\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7925 - loss: 0.4243 - val_accuracy: 0.7792 - val_loss: 0.4857\nEpoch 195/200\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8047 - loss: 0.4153 - val_accuracy: 0.7792 - val_loss: 0.4857\nEpoch 196/200\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7791 - loss: 0.4471 - val_accuracy: 0.7792 - val_loss: 0.4860\nEpoch 197/200\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7856 - loss: 0.4315 - val_accuracy: 0.7792 - val_loss: 0.4861\nEpoch 198/200\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7979 - loss: 0.4301 - val_accuracy: 0.7792 - val_loss: 0.4861\nEpoch 199/200\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8085 - loss: 0.4164 - val_accuracy: 0.7792 - val_loss: 0.4859\nEpoch 200/200\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7839 - loss: 0.4121 - val_accuracy: 0.7857 - val_loss: 0.4858\n","output_type":"stream"},{"execution_count":89,"output_type":"execute_result","data":{"text/plain":"<keras.src.callbacks.history.History at 0x7d25785f5000>"},"metadata":{}}]},{"cell_type":"code","source":"import keras_tuner as kt\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout\nfrom tensorflow.keras.optimizers import Adam, SGD, RMSprop, Adadelta\nimport numpy as np\n\n# Define the model building function\ndef build_model(hp):\n    model = Sequential()\n    \n    # Number of units in the first Dense layer, tunable between 8 and 128 with step 8\n    units = hp.Int('units', min_value=8, max_value=128, step=8)\n    \n    # Number of layers, tunable between 1 and 5\n    num_layers = hp.Int('num_layers', min_value=1, max_value=5)\n    \n    # Dropout rate, tunable between 0.1 and 0.5\n    dropout_rate = hp.Float('dropout_rate', min_value=0.1, max_value=0.5, step=0.1)\n    \n    # Input layer\n    model.add(Dense(units=units, activation='relu', input_dim=8))\n    model.add(Dropout(dropout_rate))\n    \n    # Add additional layers\n    for _ in range(num_layers - 1):  # -1 because the first layer is already added\n        model.add(Dense(units=units, activation='relu'))\n        model.add(Dropout(dropout_rate))\n    \n    # Output layer\n    model.add(Dense(1, activation='sigmoid'))\n    \n    # Optimizer selection\n    optimizer = hp.Choice('optimizer', values=['adam', 'sgd', 'rmsprop', 'adadelta'])\n    \n    if optimizer == 'adam':\n        optimizer_instance = Adam()\n    elif optimizer == 'sgd':\n        optimizer_instance = SGD()\n    elif optimizer == 'rmsprop':\n        optimizer_instance = RMSprop()\n    elif optimizer == 'adadelta':\n        optimizer_instance = Adadelta()\n    \n    model.compile(\n        optimizer=optimizer_instance,\n        loss='binary_crossentropy',\n        metrics=['accuracy']\n    )\n    \n    return model\n\n# Initialize the tuner\ntuner = kt.RandomSearch(\n    build_model,\n    objective='val_accuracy',\n    max_trials=5,\n    directory='my_dir',\n    project_name='my_project'\n)\n\n# Prepare your data (replace these with your actual data)\nX_train = np.random.random((100, 8))  # Example training data\ny_train = np.random.randint(2, size=(100, 1))  # Example training labels\nX_val = np.random.random((20, 8))    # Example validation data\ny_val = np.random.randint(2, size=(20, 1))    # Example validation labels\n\n# Perform the search with 200 epochs\ntuner.search(X_train, y_train, epochs=10, validation_data=(X_val, y_val))\n\n# Get the best model\nbest_model = tuner.get_best_models(num_models=1)[0]\n\n# Optionally, evaluate the best model on a test set\nX_test = np.random.random((20, 8))  # Example test data\ny_test = np.random.randint(2, size=(20, 1))  # Example test labels\ntest_loss, test_acc = best_model.evaluate(X_test, y_test)\nprint(f\"Test accuracy: {test_acc}\")\n\n# Retrieve the best hyperparameters\nbest_hyperparameters = tuner.get_best_hyperparameters(num_trials=1)[0]\nprint(best_hyperparameters.values)\n","metadata":{"execution":{"iopub.status.busy":"2024-07-20T08:05:48.545873Z","iopub.execute_input":"2024-07-20T08:05:48.546319Z","iopub.status.idle":"2024-07-20T08:05:50.433453Z","shell.execute_reply.started":"2024-07-20T08:05:48.546285Z","shell.execute_reply":"2024-07-20T08:05:50.431940Z"},"trusted":true},"execution_count":108,"outputs":[{"name":"stdout","text":"Reloading Tuner from my_dir/my_project/tuner0.json\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 284ms/step - accuracy: 0.5500 - loss: 0.6864\nTest accuracy: 0.550000011920929\n{'units': 48, 'num_layers': 1, 'dropout_rate': 0.2, 'optimizer': 'adam'}\n","output_type":"stream"}]},{"cell_type":"code","source":"tuner = kt.RandomSearch(\n    build_model,\n    objective='val_accuracy',\n    max_trials=5,\n    directory='my_dir',\n    project_name='Work'\n)\n\n","metadata":{"execution":{"iopub.status.busy":"2024-07-20T08:06:26.911860Z","iopub.execute_input":"2024-07-20T08:06:26.912321Z","iopub.status.idle":"2024-07-20T08:06:26.938674Z","shell.execute_reply.started":"2024-07-20T08:06:26.912286Z","shell.execute_reply":"2024-07-20T08:06:26.937586Z"},"trusted":true},"execution_count":110,"outputs":[{"name":"stdout","text":"Reloading Tuner from my_dir/Work/tuner0.json\n","output_type":"stream"}]},{"cell_type":"code","source":"tuner.search(X_train, Y_train, epochs=5, validation_data=(X_test, Y_test))","metadata":{"execution":{"iopub.status.busy":"2024-07-20T08:07:38.580062Z","iopub.execute_input":"2024-07-20T08:07:38.580525Z","iopub.status.idle":"2024-07-20T08:07:38.587577Z","shell.execute_reply.started":"2024-07-20T08:07:38.580479Z","shell.execute_reply":"2024-07-20T08:07:38.586333Z"},"trusted":true},"execution_count":113,"outputs":[]},{"cell_type":"code","source":"tuner.get_best_hyperparameters()[0].values","metadata":{"execution":{"iopub.status.busy":"2024-07-20T08:07:44.113219Z","iopub.execute_input":"2024-07-20T08:07:44.114656Z","iopub.status.idle":"2024-07-20T08:07:44.123130Z","shell.execute_reply.started":"2024-07-20T08:07:44.114601Z","shell.execute_reply":"2024-07-20T08:07:44.122017Z"},"trusted":true},"execution_count":114,"outputs":[{"execution_count":114,"output_type":"execute_result","data":{"text/plain":"{'num_layers': 6,\n 'units0': 64,\n 'optimizer': 'rmsprop',\n 'units1': 72,\n 'units2': 96,\n 'units3': 24,\n 'units4': 112,\n 'units5': 72,\n 'units6': 72,\n 'units7': 56,\n 'units8': 88,\n 'units9': 128}"},"metadata":{}}]},{"cell_type":"code","source":"print(\"X_train shape:\", X_train.shape)\nprint(\"Y_train shape:\", Y_train.shape)\nprint(\"X_test shape:\", X_test.shape)\nprint(\"Y_test shape:\", Y_test.shape)\n","metadata":{"execution":{"iopub.status.busy":"2024-07-20T08:09:21.659211Z","iopub.execute_input":"2024-07-20T08:09:21.659610Z","iopub.status.idle":"2024-07-20T08:09:21.666312Z","shell.execute_reply.started":"2024-07-20T08:09:21.659576Z","shell.execute_reply":"2024-07-20T08:09:21.665025Z"},"trusted":true},"execution_count":119,"outputs":[{"name":"stdout","text":"X_train shape: (100, 8)\nY_train shape: (614,)\nX_test shape: (20, 8)\nY_test shape: (154,)\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}